\section{Conclusion}
We presented CATANet-XS, a lightweight super-resolution model created by applying OPTIN pruning and knowledge distillation to CATANet-L. Our automated pipeline achieves 51.95\% FLOPs reduction while recovering 99.7\% of teacher performance through Output KD (38.15 dB vs 38.26 dB). Feature KD achieves comparable results at 38.09 dB, and FaKD is expected to further improve performance. This work demonstrates that automated pruning combined with KD can effectively compress Transformer-based SR models, enabling potential deployment on resource-constrained mobile devices.
