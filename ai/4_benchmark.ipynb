{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4ï¸âƒ£ Benchmark: í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ í‰ê°€\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:\n",
    "1. PTH ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ í‰ê°€ (Set5, Set14, B100, Urban100, Manga109)\n",
    "2. PTL ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ í‰ê°€\n",
    "3. ê²°ê³¼ ì €ì¥ ë° ë¹„êµ ì‹œê°í™”\n",
    "\n",
    "**í‰ê°€ ëŒ€ìƒ:**\n",
    "- ì›ë³¸ CATANet-L x2 (PTH + PTL)\n",
    "- Output KD (PTH + PTL)\n",
    "- Feature KD (PTH + PTL)\n",
    "- FaKD (PTH + PTL)\n",
    "\n",
    "**ë…¼ë¬¸ Table 2 (CATANet-L Ã—2) ê¸°ì¤€ê°’:**\n",
    "- Set5: 38.28 dB\n",
    "- Set14: 33.99 dB\n",
    "- B100: 32.37 dB\n",
    "- Urban100: 33.09 dB\n",
    "- Manga109: 39.37 dB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 í™˜ê²½ ë³€ìˆ˜ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# ìƒëŒ€ ê²½ë¡œ ì„¤ì •\n",
    "project_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "if not project_dir or project_dir == '.':\n",
    "    project_dir = os.getcwd()\n",
    "\n",
    "# ê°€ìƒí™˜ê²½ ê²½ë¡œ ì„¤ì •\n",
    "home_dir = os.path.expanduser('~')\n",
    "venv_path = os.path.join(home_dir, 'my_ssl/ssl_env')\n",
    "site_packages = os.path.join(venv_path, 'lib', 'python3.12', 'site-packages')\n",
    "python_exec = os.path.join(venv_path, 'bin', 'python')\n",
    "\n",
    "if site_packages not in sys.path:\n",
    "    sys.path.insert(0, site_packages)\n",
    "\n",
    "%cd {project_dir}\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "os.makedirs('results/benchmark', exist_ok=True)\n",
    "\n",
    "print(f\"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ: {project_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 í‰ê°€ ëŒ€ìƒ ëª¨ë¸ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ğŸ“ í‰ê°€ ëŒ€ìƒ ëª¨ë¸ í™•ì¸\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# PTH ëª¨ë¸\n",
    "pth_models = [\n",
    "    ('Original', 'weights/CATANet-L_x2.pth'),\n",
    "    ('Output_KD', 'weights/finetuned_output.pth'),\n",
    "    ('Feature_KD', 'weights/finetuned_feature.pth'),\n",
    "    ('FaKD', 'weights/finetuned_fakd.pth'),\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ”¹ PTH ëª¨ë¸:\")\n",
    "for name, path in pth_models:\n",
    "    if os.path.exists(path):\n",
    "        size = os.path.getsize(path) / (1024 * 1024)\n",
    "        print(f\"   âœ… {name:12} | {path} ({size:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"   âŒ {name:12} | {path} (ì—†ìŒ)\")\n",
    "\n",
    "# PTL ëª¨ë¸\n",
    "print(\"\\nğŸ”¹ PTL ëª¨ë¸:\")\n",
    "ptl_count = 0\n",
    "if os.path.exists('weights'):\n",
    "    ptl_files = [f for f in os.listdir('weights') if f.endswith('.ptl')]\n",
    "    for f in sorted(ptl_files):\n",
    "        size = os.path.getsize(f'weights/{f}') / (1024 * 1024)\n",
    "        print(f\"   âœ… {f} ({size:.1f} MB)\")\n",
    "        ptl_count += 1\n",
    "    if ptl_count == 0:\n",
    "        print(\"   âŒ PTL íŒŒì¼ ì—†ìŒ\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ì´ PTL íŒŒì¼: {ptl_count}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_dir = os.path.join(project_dir, 'datasets/benchmark')\n",
    "\n",
    "print(\"ğŸ“ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ í™•ì¸:\")\n",
    "if os.path.exists(benchmark_dir):\n",
    "    !ls -la {benchmark_dir}\n",
    "else:\n",
    "    print(\"âš ï¸ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    print(\"   1_setup.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.3 PTH ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ğŸ¯ PTH ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ í‰ê°€\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ“Š ë…¼ë¬¸ ê¸°ì¤€ê°’ (CATANet-L Ã—2):\")\n",
    "print(\"   Set5: 38.28 | Set14: 33.99 | B100: 32.37 | Urban100: 33.09 | Manga109: 39.37\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# í‰ê°€í•  PTH ëª¨ë¸ ëª©ë¡\n",
    "pth_models = [\n",
    "    ('Original', 'weights/CATANet-L_x2.pth'),\n",
    "    ('Output_KD', 'weights/finetuned_output.pth'),\n",
    "    ('Feature_KD', 'weights/finetuned_feature.pth'),\n",
    "    ('FaKD', 'weights/finetuned_fakd.pth'),\n",
    "]\n",
    "\n",
    "output_csv = 'results/benchmark/pth_benchmark_results.csv'\n",
    "\n",
    "for name, path in pth_models:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"\\n{'#'*60}\")\n",
    "        print(f\"# {name}: {path}\")\n",
    "        print(f\"{'#'*60}\")\n",
    "        \n",
    "        !{python_exec} evaluate_benchmark.py \\\n",
    "            --weights {path} \\\n",
    "            --benchmark_dir datasets/benchmark \\\n",
    "            --scale 2 \\\n",
    "            --model_name \"{name}_PTH\" \\\n",
    "            --output {output_csv}\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ {name} ì—†ìŒ: {path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"âœ… PTH ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì €ì¥: {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.4 PTL ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ í‰ê°€\n",
    "\n",
    "PTL íŒŒì¼ì€ traceëœ ê³ ì • ì…ë ¥ í¬ê¸°ì—ì„œë§Œ ë™ì‘í•˜ë¯€ë¡œ, ë²¤ì¹˜ë§ˆí¬ í‰ê°€ ì‹œ ì´ë¯¸ì§€ë¥¼ í•´ë‹¹ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆí•˜ì—¬ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PTL ë²¤ì¹˜ë§ˆí¬ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±\n",
    "ptl_benchmark_script = '''\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def rgb2ycbcr(img):\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img = img.cpu().numpy()\n",
    "    if img.ndim == 4:\n",
    "        img = img[0]\n",
    "    if img.shape[0] == 3:\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "    img = img.astype(np.float64)\n",
    "    y = 16. + (65.481 * img[:,:,0] + 128.553 * img[:,:,1] + 24.966 * img[:,:,2]) / 255.\n",
    "    return y\n",
    "\n",
    "\n",
    "def calculate_psnr(img1, img2, border=0):\n",
    "    if border > 0:\n",
    "        img1 = img1[border:-border, border:-border]\n",
    "        img2 = img2[border:-border, border:-border]\n",
    "    mse = np.mean((img1.astype(np.float64) - img2.astype(np.float64)) ** 2)\n",
    "    if mse == 0:\n",
    "        return float(\"inf\")\n",
    "    return 20 * np.log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--ptl_path\", type=str, required=True)\n",
    "    parser.add_argument(\"--input_size\", type=int, required=True)\n",
    "    parser.add_argument(\"--benchmark_dir\", type=str, default=\"datasets/benchmark\")\n",
    "    parser.add_argument(\"--scale\", type=int, default=2)\n",
    "    parser.add_argument(\"--output\", type=str, default=\"results/benchmark/ptl_benchmark_results.csv\")\n",
    "    parser.add_argument(\"--model_name\", type=str, default=\"PTL_Model\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Input size: {args.input_size}x{args.input_size}\")\n",
    "    \n",
    "    print(f\"Loading: {args.ptl_path}\")\n",
    "    model = torch.jit.load(args.ptl_path, map_location=device)\n",
    "    model.eval()\n",
    "    \n",
    "    datasets = [\"Set5\", \"Set14\"]\n",
    "    results = {}\n",
    "    inference_times = []\n",
    "    \n",
    "    print(f\"\\\\n{\"=\"*50}\")\n",
    "    print(f\"Benchmark Evaluation (Scale: x{args.scale})\")\n",
    "    print(f\"{\"=\"*50}\")\n",
    "    \n",
    "    for ds in datasets:\n",
    "        ds_path = os.path.join(args.benchmark_dir, ds)\n",
    "        hr_dir = os.path.join(ds_path, \"HR\")\n",
    "        lr_dir = os.path.join(ds_path, f\"LR_bicubic\", f\"X{args.scale}\")\n",
    "        \n",
    "        if not os.path.exists(hr_dir) or not os.path.exists(lr_dir):\n",
    "            continue\n",
    "        \n",
    "        hr_images = sorted([f for f in os.listdir(hr_dir) if f.endswith((\".png\", \".jpg\", \".bmp\"))])\n",
    "        psnr_list = []\n",
    "        \n",
    "        for hr_name in tqdm(hr_images, desc=ds, leave=False):\n",
    "            base_name = os.path.splitext(hr_name)[0]\n",
    "            lr_path = os.path.join(lr_dir, f\"{base_name}x{args.scale}.png\")\n",
    "            hr_path = os.path.join(hr_dir, hr_name)\n",
    "            \n",
    "            if not os.path.exists(lr_path):\n",
    "                continue\n",
    "            \n",
    "            lr_pil = Image.open(lr_path).convert(\"RGB\")\n",
    "            lr_resized = lr_pil.resize((args.input_size, args.input_size), Image.BICUBIC)\n",
    "            lr_np = np.array(lr_resized).astype(np.float32) / 255.0\n",
    "            lr_tensor = torch.from_numpy(np.transpose(lr_np, (2, 0, 1))).unsqueeze(0)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                sr_tensor = model(lr_tensor).clamp(0, 1)\n",
    "            inference_times.append(time.time() - start_time)\n",
    "            \n",
    "            hr_pil = Image.open(hr_path).convert(\"RGB\")\n",
    "            hr_resized = hr_pil.resize((args.input_size * args.scale, args.input_size * args.scale), Image.BICUBIC)\n",
    "            hr_np = np.array(hr_resized).astype(np.float32) / 255.0\n",
    "            \n",
    "            sr_y = rgb2ycbcr(sr_tensor.numpy()[0] * 255)\n",
    "            hr_y = rgb2ycbcr(np.transpose(hr_np, (2, 0, 1)) * 255)\n",
    "            \n",
    "            psnr_list.append(calculate_psnr(sr_y, hr_y, border=args.scale))\n",
    "        \n",
    "        if psnr_list:\n",
    "            results[ds] = np.mean(psnr_list)\n",
    "            print(f\"{ds:12} PSNR: {results[ds]:.4f} dB\")\n",
    "    \n",
    "    avg_time = np.mean(inference_times) * 1000 if inference_times else 0\n",
    "    print(f\"\\\\nAvg inference time: {avg_time:.2f} ms\")\n",
    "    \n",
    "    os.makedirs(os.path.dirname(args.output), exist_ok=True)\n",
    "    file_exists = os.path.exists(args.output)\n",
    "    with open(args.output, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        if not file_exists:\n",
    "            header = [\"Timestamp\", \"Model\", \"Input_Size\", \"Set5_PSNR\", \"Set14_PSNR\", \"Avg_Time_ms\"]\n",
    "            writer.writerow(header)\n",
    "        \n",
    "        row = [\n",
    "            datetime.now().strftime(\"%Y-%m-%d %H:%M\"),\n",
    "            args.model_name,\n",
    "            args.input_size,\n",
    "            f\"{results.get(\"Set5\", 0):.4f}\",\n",
    "            f\"{results.get(\"Set14\", 0):.4f}\",\n",
    "            f\"{avg_time:.2f}\"\n",
    "        ]\n",
    "        writer.writerow(row)\n",
    "    \n",
    "    print(f\"\\\\nâœ… Results saved to {args.output}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "script_path = os.path.join(project_dir, 'evaluate_ptl_benchmark.py')\n",
    "with open(script_path, 'w') as f:\n",
    "    content = ptl_benchmark_script.replace('\\\\n', '\\n').replace('\\\\\"', '\"')\n",
    "    f.write(content)\n",
    "\n",
    "print(f\"âœ… PTL ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: {script_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ğŸ¯ PTL ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ í‰ê°€\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# PTL íŒŒì¼ ëª©ë¡\n",
    "ptl_models = []\n",
    "if os.path.exists('weights'):\n",
    "    for f in os.listdir('weights'):\n",
    "        if f.endswith('.ptl'):\n",
    "            parts = f.replace('.ptl', '').split('_')\n",
    "            try:\n",
    "                input_size = int(parts[-1])\n",
    "                model_name = '_'.join(parts[:-1])\n",
    "                ptl_models.append((model_name, f'weights/{f}', input_size))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "output_csv = 'results/benchmark/ptl_benchmark_results.csv'\n",
    "\n",
    "if len(ptl_models) == 0:\n",
    "    print(\"âš ï¸ PTL íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    print(\"   1_setup.ipynbì™€ 3_ptl.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    ptl_models.sort(key=lambda x: (x[0], x[2]))\n",
    "    \n",
    "    for model_name, ptl_path, input_size in ptl_models:\n",
    "        print(f\"\\n{'#'*60}\")\n",
    "        print(f\"# {model_name} (ì…ë ¥: {input_size}x{input_size})\")\n",
    "        print(f\"{'#'*60}\")\n",
    "        \n",
    "        !{python_exec} evaluate_ptl_benchmark.py \\\n",
    "            --ptl_path {ptl_path} \\\n",
    "            --input_size {input_size} \\\n",
    "            --benchmark_dir datasets/benchmark \\\n",
    "            --scale 2 \\\n",
    "            --model_name \"{model_name}\" \\\n",
    "            --output {output_csv}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"âœ… PTL ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì €ì¥: {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.5 ê²°ê³¼ ë¹„êµ í…Œì´ë¸”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¹„êµ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# PTH ê²°ê³¼\n",
    "pth_results = 'results/benchmark/pth_benchmark_results.csv'\n",
    "if os.path.exists(pth_results):\n",
    "    print(\"\\nğŸ”¹ PTH ëª¨ë¸ ê²°ê³¼:\")\n",
    "    df_pth = pd.read_csv(pth_results)\n",
    "    display(df_pth)\n",
    "else:\n",
    "    print(\"\\nâš ï¸ PTH ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì—†ìŒ\")\n",
    "\n",
    "# PTL ê²°ê³¼\n",
    "ptl_results = 'results/benchmark/ptl_benchmark_results.csv'\n",
    "if os.path.exists(ptl_results):\n",
    "    print(\"\\nğŸ”¹ PTL ëª¨ë¸ ê²°ê³¼:\")\n",
    "    df_ptl = pd.read_csv(ptl_results)\n",
    "    display(df_ptl)\n",
    "else:\n",
    "    print(\"\\nâš ï¸ PTL ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì—†ìŒ\")\n",
    "\n",
    "# ë…¼ë¬¸ ê¸°ì¤€ê°’\n",
    "print(\"\\nğŸ”¹ ë…¼ë¬¸ ê¸°ì¤€ê°’ (CATANet-L Ã—2):\")\n",
    "print(\"   Set5: 38.28 | Set14: 33.99 | B100: 32.37 | Urban100: 33.09 | Manga109: 39.37\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.6 ê²°ê³¼ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì‹œê°í™”\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# PTH ê²°ê³¼ ì‹œê°í™”\n",
    "pth_results = 'results/benchmark/pth_benchmark_results.csv'\n",
    "if os.path.exists(pth_results):\n",
    "    df = pd.read_csv(pth_results)\n",
    "    \n",
    "    paper = {'Set5': 38.28, 'Set14': 33.99, 'B100': 32.37, 'Urban100': 33.09, 'Manga109': 39.37}\n",
    "    datasets = ['Set5', 'Set14', 'B100', 'Urban100', 'Manga109']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    x = np.arange(len(datasets))\n",
    "    width = 0.15\n",
    "    \n",
    "    paper_vals = [paper[ds] for ds in datasets]\n",
    "    ax.bar(x - width*2, paper_vals, width, label='Paper', color='gray', alpha=0.7)\n",
    "    \n",
    "    colors = ['#3B82F6', '#10B981', '#F59E0B', '#EF4444']\n",
    "    for idx, (_, row) in enumerate(df.iterrows()):\n",
    "        if idx >= len(colors):\n",
    "            break\n",
    "        vals = []\n",
    "        for ds in datasets:\n",
    "            col = f'{ds}_PSNR'\n",
    "            try:\n",
    "                vals.append(float(row[col]) if col in row and pd.notna(row[col]) and row[col] != 'N/A' else 0)\n",
    "            except:\n",
    "                vals.append(0)\n",
    "        ax.bar(x + width*(idx-1), vals, width, label=row['Model'], color=colors[idx])\n",
    "    \n",
    "    ax.set_ylabel('PSNR (dB)', fontsize=12)\n",
    "    ax.set_xlabel('Dataset', fontsize=12)\n",
    "    ax.set_title('PTH Model Benchmark Comparison', fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(datasets)\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.set_ylim(30, 42)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/benchmark/pth_comparison.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nâœ… ê·¸ë˜í”„ ì €ì¥: results/benchmark/pth_comparison.png\")\n",
    "else:\n",
    "    print(\"âš ï¸ PTH ê²°ê³¼ íŒŒì¼ ì—†ìŒ\")\n",
    "\n",
    "# PTL ì¶”ë¡  ì‹œê°„ ë¹„êµ\n",
    "ptl_results = 'results/benchmark/ptl_benchmark_results.csv'\n",
    "if os.path.exists(ptl_results):\n",
    "    df_ptl = pd.read_csv(ptl_results)\n",
    "    \n",
    "    if len(df_ptl) > 0:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        models = df_ptl['Model'].unique()\n",
    "        colors = plt.cm.Set2(np.linspace(0, 1, len(models)))\n",
    "        \n",
    "        for idx, model in enumerate(models):\n",
    "            model_data = df_ptl[df_ptl['Model'] == model].sort_values('Input_Size')\n",
    "            ax.plot(model_data['Input_Size'], model_data['Avg_Time_ms'], \n",
    "                    marker='o', label=model, color=colors[idx], linewidth=2)\n",
    "        \n",
    "        ax.set_xlabel('Input Size', fontsize=12)\n",
    "        ax.set_ylabel('Inference Time (ms)', fontsize=12)\n",
    "        ax.set_title('PTL Model Inference Time Comparison', fontsize=14)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/benchmark/ptl_inference_time.png', dpi=150)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nâœ… ê·¸ë˜í”„ ì €ì¥: results/benchmark/ptl_inference_time.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.7 ìµœì¢… ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“Š ìµœì¢… ë²¤ì¹˜ë§ˆí¬ ìš”ì•½\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ê²°ê³¼ íŒŒì¼ í™•ì¸\n",
    "print(\"\\nğŸ“ ìƒì„±ëœ ê²°ê³¼ íŒŒì¼:\")\n",
    "!ls -lh results/benchmark/ 2>/dev/null || echo \"   ê²°ê³¼ íŒŒì¼ ì—†ìŒ\"\n",
    "\n",
    "# PTH ìš”ì•½\n",
    "pth_results = 'results/benchmark/pth_benchmark_results.csv'\n",
    "if os.path.exists(pth_results):\n",
    "    df = pd.read_csv(pth_results)\n",
    "    print(\"\\nğŸ”¹ PTH ëª¨ë¸ Set5 PSNR:\")\n",
    "    for _, row in df.iterrows():\n",
    "        if 'Set5_PSNR' in row and pd.notna(row['Set5_PSNR']):\n",
    "            try:\n",
    "                psnr = float(row['Set5_PSNR'])\n",
    "                print(f\"   {row['Model']:20} | {psnr:.4f} dB\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# PTL ìš”ì•½\n",
    "ptl_results = 'results/benchmark/ptl_benchmark_results.csv'\n",
    "if os.path.exists(ptl_results):\n",
    "    df = pd.read_csv(ptl_results)\n",
    "    print(\"\\nğŸ”¹ PTL ëª¨ë¸ ì¶”ë¡  ì‹œê°„ (640x640 ê¸°ì¤€):\")\n",
    "    df_640 = df[df['Input_Size'] == 640]\n",
    "    for _, row in df_640.iterrows():\n",
    "        print(f\"   {row['Model']:20} | {row['Avg_Time_ms']:.2f} ms\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ë²¤ì¹˜ë§ˆí¬ í‰ê°€ ì™„ë£Œ!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
