{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4ï¸âƒ£ Benchmark: í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ í‰ê°€\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:\n",
    "1. PTH ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ í‰ê°€ (Set5, Set14, B100, Urban100, Manga109)\n",
    "2. PTL ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ í‰ê°€\n",
    "3. ê²°ê³¼ ì €ì¥ ë° ë¹„êµ ì‹œê°í™”\n",
    "\n",
    "**í‰ê°€ ëŒ€ìƒ:**\n",
    "- ì›ë³¸ CATANet-L x2 (PTH + PTL)\n",
    "- Output KD (PTH + PTL)\n",
    "- Feature KD (PTH + PTL)\n",
    "- FaKD (PTH + PTL)\n",
    "\n",
    "**ë…¼ë¬¸ Table 2 (CATANet-L Ã—2) ê¸°ì¤€ê°’:**\n",
    "- Set5: 38.28 dB\n",
    "- Set14: 33.99 dB\n",
    "- B100: 32.37 dB\n",
    "- Urban100: 33.09 dB\n",
    "- Manga109: 39.37 dB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## âš™ï¸ 0. ê²½ë¡œ ì„¤ì • (ì´ ì…€ë§Œ ìˆ˜ì •í•˜ì„¸ìš”!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ğŸ”§ ì‚¬ìš©ì ì„¤ì • - 1_setup.ipynbì™€ ë™ì¼í•˜ê²Œ!\n",
    "# ============================================================\n",
    "BASE_DIR = \"my_ssl\"\n",
    "VENV_NAME = \"ssl_env\"\n",
    "PYTHON_VERSION = \"3.12\"\n",
    "REPO_NAME = \"uos-ssl-project\"\n",
    "\n",
    "# ============================================================\n",
    "# ğŸ”’ ì•„ë˜ëŠ” ìë™ ì„¤ì • (ìˆ˜ì • ë¶ˆí•„ìš”)\n",
    "# ============================================================\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "os.environ['MPLBACKEND'] = 'Agg'\n",
    "\n",
    "home_dir = os.path.expanduser('~')\n",
    "base_path = os.path.join(home_dir, BASE_DIR)\n",
    "venv_path = os.path.join(base_path, VENV_NAME)\n",
    "site_packages = os.path.join(venv_path, 'lib', f'python{PYTHON_VERSION}', 'site-packages')\n",
    "python_exec = os.path.join(venv_path, 'bin', 'python')\n",
    "project_dir = os.path.join(base_path, REPO_NAME)\n",
    "ai_dir = os.path.join(project_dir, 'ai')\n",
    "\n",
    "if site_packages not in sys.path:\n",
    "    sys.path.insert(0, site_packages)\n",
    "\n",
    "%cd {ai_dir}\n",
    "\n",
    "os.makedirs('results/benchmark', exist_ok=True)\n",
    "\n",
    "# ê²½ë¡œ ê²€ì¦\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ” ê²½ë¡œ ê²€ì¦\")\n",
    "print(\"=\"*60)\n",
    "paths_ok = True\n",
    "for name, path in [(\"AI Dir\", ai_dir), (\"Python\", python_exec), (\"Venv\", venv_path)]:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"âœ… {name}: {path}\")\n",
    "    else:\n",
    "        print(f\"âŒ {name}: {path} (ì—†ìŒ!)\")\n",
    "        paths_ok = False\n",
    "\n",
    "if not paths_ok:\n",
    "    raise RuntimeError(\"ê²½ë¡œ ì„¤ì • ì˜¤ë¥˜! ìœ„ì˜ ì‚¬ìš©ì ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜\n",
    "# ============================================================\n",
    "def run_benchmark(cmd, task_name):\n",
    "    \"\"\"ë²¤ì¹˜ë§ˆí¬ ëª…ë ¹ ì‹¤í–‰ í›„ ì—ëŸ¬ ì²´í¬\"\"\"\n",
    "    result = subprocess.run(cmd, cwd=ai_dir)\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        print(f\"âŒ {task_name} ì‹¤íŒ¨! (exit code: {result.returncode})\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"âœ… {task_name} ì™„ë£Œ!\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 í‰ê°€ ëŒ€ìƒ ëª¨ë¸ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ğŸ“ í‰ê°€ ëŒ€ìƒ ëª¨ë¸ í™•ì¸\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "pth_models = [\n",
    "    ('Original', 'weights/CATANet-L_x2.pth'),\n",
    "    ('Output_KD', 'weights/finetuned_output.pth'),\n",
    "    ('Feature_KD', 'weights/finetuned_feature.pth'),\n",
    "    ('FaKD', 'weights/finetuned_fakd.pth'),\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ”¹ PTH ëª¨ë¸:\")\n",
    "available_pth = []\n",
    "for name, path in pth_models:\n",
    "    full_path = os.path.join(ai_dir, path)\n",
    "    if os.path.exists(full_path):\n",
    "        size = os.path.getsize(full_path) / (1024 * 1024)\n",
    "        print(f\"   âœ… {name:12} | {path} ({size:.1f} MB)\")\n",
    "        available_pth.append((name, path))\n",
    "    else:\n",
    "        print(f\"   âŒ {name:12} | {path} (ì—†ìŒ)\")\n",
    "\n",
    "print(\"\\nğŸ”¹ PTL ëª¨ë¸:\")\n",
    "weights_dir = os.path.join(ai_dir, 'weights')\n",
    "ptl_count = 0\n",
    "if os.path.exists(weights_dir):\n",
    "    ptl_files = sorted([f for f in os.listdir(weights_dir) if f.endswith('.ptl')])\n",
    "    for f in ptl_files:\n",
    "        path = os.path.join(weights_dir, f)\n",
    "        size = os.path.getsize(path) / (1024 * 1024)\n",
    "        print(f\"   âœ… {f} ({size:.1f} MB)\")\n",
    "        ptl_count += 1\n",
    "    if ptl_count == 0:\n",
    "        print(\"   âŒ PTL íŒŒì¼ ì—†ìŒ\")\n",
    "\n",
    "print(f\"\\nğŸ“Š PTH: {len(available_pth)}ê°œ, PTL: {ptl_count}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_dir = os.path.join(ai_dir, 'datasets/benchmark')\n",
    "\n",
    "print(\"ğŸ“ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ í™•ì¸:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "expected_datasets = ['Set5', 'Set14', 'B100', 'Urban100', 'Manga109']\n",
    "all_exist = True\n",
    "\n",
    "if os.path.exists(benchmark_dir):\n",
    "    for ds in expected_datasets:\n",
    "        ds_path = os.path.join(benchmark_dir, ds)\n",
    "        if os.path.exists(ds_path):\n",
    "            print(f\"   âœ… {ds}\")\n",
    "        else:\n",
    "            print(f\"   âŒ {ds} (ì—†ìŒ)\")\n",
    "            all_exist = False\n",
    "else:\n",
    "    print(\"âŒ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    print(\"   1_setup.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "    all_exist = False\n",
    "\n",
    "if all_exist:\n",
    "    print(\"\\nâœ… ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ ì¤€ë¹„ë¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.3 PTH ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ğŸ¯ PTH ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ í‰ê°€\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ“Š ë…¼ë¬¸ ê¸°ì¤€ê°’ (CATANet-L Ã—2):\")\n",
    "print(\"   Set5: 38.28 | Set14: 33.99 | B100: 32.37 | Urban100: 33.09 | Manga109: 39.37\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "pth_models = [\n",
    "    ('Original', 'weights/CATANet-L_x2.pth'),\n",
    "    ('Output_KD', 'weights/finetuned_output.pth'),\n",
    "    ('Feature_KD', 'weights/finetuned_feature.pth'),\n",
    "    ('FaKD', 'weights/finetuned_fakd.pth'),\n",
    "]\n",
    "\n",
    "output_csv = 'results/benchmark/pth_benchmark_results.csv'\n",
    "success_count = 0\n",
    "fail_count = 0\n",
    "\n",
    "for name, path in pth_models:\n",
    "    full_path = os.path.join(ai_dir, path)\n",
    "    if os.path.exists(full_path):\n",
    "        print(f\"\\n{'#'*60}\")\n",
    "        print(f\"# {name}: {path}\")\n",
    "        print(f\"{'#'*60}\")\n",
    "        \n",
    "        cmd = [\n",
    "            python_exec, 'evaluate_benchmark.py',\n",
    "            '--weights', path,\n",
    "            '--benchmark_dir', 'datasets/benchmark',\n",
    "            '--scale', '2',\n",
    "            '--model_name', f'{name}_PTH',\n",
    "            '--output', output_csv\n",
    "        ]\n",
    "        \n",
    "        if run_benchmark(cmd, f\"{name} í‰ê°€\"):\n",
    "            success_count += 1\n",
    "        else:\n",
    "            fail_count += 1\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ {name} ì—†ìŒ: {path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if fail_count == 0 and success_count > 0:\n",
    "    print(f\"âœ… PTH ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ! ({success_count}ê°œ ëª¨ë¸)\")\n",
    "    print(f\"   ê²°ê³¼ ì €ì¥: {output_csv}\")\n",
    "elif fail_count > 0:\n",
    "    print(f\"âš ï¸ PTH ë²¤ì¹˜ë§ˆí¬ ì¼ë¶€ ì‹¤íŒ¨! ({success_count} ì„±ê³µ, {fail_count} ì‹¤íŒ¨)\")\n",
    "else:\n",
    "    print(\"âš ï¸ í‰ê°€í•  PTH ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.4 PTL ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ğŸ¯ PTL ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ í‰ê°€\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# PTL ëª¨ë¸ ëª©ë¡ ìˆ˜ì§‘\n",
    "ptl_models = []\n",
    "weights_dir = os.path.join(ai_dir, 'weights')\n",
    "\n",
    "if os.path.exists(weights_dir):\n",
    "    for f in os.listdir(weights_dir):\n",
    "        if f.endswith('.ptl'):\n",
    "            parts = f.replace('.ptl', '').split('_')\n",
    "            try:\n",
    "                input_size = int(parts[-1])\n",
    "                model_name = '_'.join(parts[:-1])\n",
    "                ptl_models.append((model_name, f'weights/{f}', input_size))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "output_csv = 'results/benchmark/ptl_benchmark_results.csv'\n",
    "\n",
    "if len(ptl_models) == 0:\n",
    "    print(\"âš ï¸ PTL íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    print(\"   1_setup.ipynbì™€ 3_ptl.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    ptl_models.sort(key=lambda x: (x[0], x[2]))\n",
    "    \n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    \n",
    "    for model_name, ptl_path, input_size in ptl_models:\n",
    "        print(f\"\\n{'#'*60}\")\n",
    "        print(f\"# {model_name} (ì…ë ¥: {input_size}x{input_size})\")\n",
    "        print(f\"{'#'*60}\")\n",
    "        \n",
    "        cmd = [\n",
    "            python_exec, 'evaluate_ptl_benchmark.py',\n",
    "            '--ptl_path', ptl_path,\n",
    "            '--input_size', str(input_size),\n",
    "            '--benchmark_dir', 'datasets/benchmark',\n",
    "            '--scale', '2',\n",
    "            '--model_name', model_name,\n",
    "            '--output', output_csv\n",
    "        ]\n",
    "        \n",
    "        if run_benchmark(cmd, f\"{model_name}_{input_size} í‰ê°€\"):\n",
    "            success_count += 1\n",
    "        else:\n",
    "            fail_count += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    if fail_count == 0:\n",
    "        print(f\"âœ… PTL ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ! ({success_count}ê°œ ëª¨ë¸)\")\n",
    "        print(f\"   ê²°ê³¼ ì €ì¥: {output_csv}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ PTL ë²¤ì¹˜ë§ˆí¬ ì¼ë¶€ ì‹¤íŒ¨! ({success_count} ì„±ê³µ, {fail_count} ì‹¤íŒ¨)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.5 ê²°ê³¼ ë¹„êµ í…Œì´ë¸”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¹„êµ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "pth_results = os.path.join(ai_dir, 'results/benchmark/pth_benchmark_results.csv')\n",
    "if os.path.exists(pth_results):\n",
    "    print(\"\\nğŸ”¹ PTH ëª¨ë¸ ê²°ê³¼:\")\n",
    "    df_pth = pd.read_csv(pth_results)\n",
    "    display(df_pth)\n",
    "else:\n",
    "    print(\"\\nâš ï¸ PTH ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì—†ìŒ\")\n",
    "\n",
    "ptl_results = os.path.join(ai_dir, 'results/benchmark/ptl_benchmark_results.csv')\n",
    "if os.path.exists(ptl_results):\n",
    "    print(\"\\nğŸ”¹ PTL ëª¨ë¸ ê²°ê³¼:\")\n",
    "    df_ptl = pd.read_csv(ptl_results)\n",
    "    display(df_ptl)\n",
    "else:\n",
    "    print(\"\\nâš ï¸ PTL ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì—†ìŒ\")\n",
    "\n",
    "print(\"\\nğŸ”¹ ë…¼ë¬¸ ê¸°ì¤€ê°’ (CATANet-L Ã—2):\")\n",
    "print(\"   Set5: 38.28 | Set14: 33.99 | B100: 32.37 | Urban100: 33.09 | Manga109: 39.37\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.6 ê²°ê³¼ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì‹œê°í™”\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pth_results = os.path.join(ai_dir, 'results/benchmark/pth_benchmark_results.csv')\n",
    "if os.path.exists(pth_results):\n",
    "    df = pd.read_csv(pth_results)\n",
    "    \n",
    "    paper = {'Set5': 38.28, 'Set14': 33.99, 'B100': 32.37, 'Urban100': 33.09, 'Manga109': 39.37}\n",
    "    datasets = ['Set5', 'Set14', 'B100', 'Urban100', 'Manga109']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    x = np.arange(len(datasets))\n",
    "    width = 0.15\n",
    "    \n",
    "    paper_vals = [paper[ds] for ds in datasets]\n",
    "    ax.bar(x - width*2, paper_vals, width, label='Paper', color='gray', alpha=0.7)\n",
    "    \n",
    "    colors = ['#3B82F6', '#10B981', '#F59E0B', '#EF4444']\n",
    "    for idx, (_, row) in enumerate(df.iterrows()):\n",
    "        if idx >= len(colors):\n",
    "            break\n",
    "        vals = []\n",
    "        for ds in datasets:\n",
    "            col = f'{ds}_PSNR'\n",
    "            try:\n",
    "                vals.append(float(row[col]) if col in row and pd.notna(row[col]) else 0)\n",
    "            except:\n",
    "                vals.append(0)\n",
    "        ax.bar(x + width*(idx-1), vals, width, label=row['Model'], color=colors[idx])\n",
    "    \n",
    "    ax.set_ylabel('PSNR (dB)')\n",
    "    ax.set_xlabel('Dataset')\n",
    "    ax.set_title('PTH Model Benchmark')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(datasets)\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.set_ylim(30, 42)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(ai_dir, 'results/benchmark/pth_comparison.png')\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.show()\n",
    "    print(f\"\\nâœ… ì €ì¥: {save_path}\")\n",
    "else:\n",
    "    print(\"âš ï¸ PTH ê²°ê³¼ ì—†ìŒ\")\n",
    "\n",
    "ptl_results = os.path.join(ai_dir, 'results/benchmark/ptl_benchmark_results.csv')\n",
    "if os.path.exists(ptl_results):\n",
    "    df_ptl = pd.read_csv(ptl_results)\n",
    "    if len(df_ptl) > 0 and 'Avg_Time_ms' in df_ptl.columns:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        models = df_ptl['Model'].unique()\n",
    "        colors = plt.cm.Set2(np.linspace(0, 1, len(models)))\n",
    "        \n",
    "        for idx, model in enumerate(models):\n",
    "            data = df_ptl[df_ptl['Model'] == model].sort_values('Input_Size')\n",
    "            ax.plot(data['Input_Size'], data['Avg_Time_ms'], \n",
    "                    marker='o', label=model, color=colors[idx], linewidth=2)\n",
    "        \n",
    "        ax.set_xlabel('Input Size')\n",
    "        ax.set_ylabel('Inference Time (ms)')\n",
    "        ax.set_title('PTL Inference Time')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(ai_dir, 'results/benchmark/ptl_inference_time.png')\n",
    "        plt.savefig(save_path, dpi=150)\n",
    "        plt.show()\n",
    "        print(f\"\\nâœ… ì €ì¥: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.7 ìµœì¢… ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“Š ìµœì¢… ë²¤ì¹˜ë§ˆí¬ ìš”ì•½\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_dir = os.path.join(ai_dir, 'results/benchmark')\n",
    "print(\"\\nğŸ“ ìƒì„±ëœ ê²°ê³¼ íŒŒì¼:\")\n",
    "if os.path.exists(results_dir):\n",
    "    files = os.listdir(results_dir)\n",
    "    if files:\n",
    "        for f in sorted(files):\n",
    "            path = os.path.join(results_dir, f)\n",
    "            size = os.path.getsize(path) / 1024\n",
    "            print(f\"   {f} ({size:.1f} KB)\")\n",
    "    else:\n",
    "        print(\"   ì—†ìŒ\")\n",
    "else:\n",
    "    print(\"   ì—†ìŒ\")\n",
    "\n",
    "pth_results = os.path.join(ai_dir, 'results/benchmark/pth_benchmark_results.csv')\n",
    "if os.path.exists(pth_results):\n",
    "    df = pd.read_csv(pth_results)\n",
    "    print(\"\\nğŸ”¹ PTH ëª¨ë¸ Set5 PSNR:\")\n",
    "    for _, row in df.iterrows():\n",
    "        if 'Set5_PSNR' in row and pd.notna(row['Set5_PSNR']):\n",
    "            try:\n",
    "                print(f\"   {row['Model']:20} | {float(row['Set5_PSNR']):.4f} dB\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "ptl_results = os.path.join(ai_dir, 'results/benchmark/ptl_benchmark_results.csv')\n",
    "if os.path.exists(ptl_results):\n",
    "    df = pd.read_csv(ptl_results)\n",
    "    if 'Input_Size' in df.columns and 'Avg_Time_ms' in df.columns:\n",
    "        print(\"\\nğŸ”¹ PTL ì¶”ë¡  ì‹œê°„ (640x640):\")\n",
    "        df_640 = df[df['Input_Size'] == 640]\n",
    "        for _, row in df_640.iterrows():\n",
    "            print(f\"   {row['Model']:20} | {row['Avg_Time_ms']:.2f} ms\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
